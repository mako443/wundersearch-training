# Wundersearch Training
Model training for the WunderSearch text-to-image search app.

# CoreML Deploy
- Multiple models
- TODO: verify outputs python/iOS -> Similar but slightly different, that ok?
- Maybe .json file for handling?

# TODO
Training
- Don't train the image model? Only lower layers?
- Random-search LR vs. margin
- Larger image model (check iOS runtime)
- Reduce words to cover 90-95% occurences
- Use GLoVE?

General
- PWR or HRL loss?
- Quantize models?
- Use VSE and detection ensemble?
- Use stronger cross-modal model? (Pre-trained possible?)
